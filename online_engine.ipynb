{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online movie recommending service using Spark and Flask\n",
    "\n",
    "To make our movie recommender a online service, we can use the python-based framework [Flask](http://flask.pocoo.org/). This can be used to build web-services on top of any kind of Spark models. \n",
    "\n",
    "The complete web service contains three Python files:\n",
    "- recommender.py defines the recommender engine, it contains all the Spark related computation.\n",
    "- app.py is a Flask web application that defines a restful-like API around the engine.\n",
    "- server.py initialize a CherryPy webserver after creating a Spark context and Flask web application.\n",
    "\n",
    "## A recommendation engine\n",
    "\n",
    "The core of our movie recommendation web service is the recommendation model we built. It is represented by the class RecommendationEngion.\n",
    "\n",
    "### Starting the engine\n",
    "\n",
    "\n",
    "When the engine is initialized, we need to generate the ALS model for the first time. Optionally we might want to load a previously built model, we might even want to load or precompute any RDDs that will be used later to make recommendations.\n",
    "\n",
    "We'll do that in the \\__init\\__ method. In this case, we won't save any time. The same process is repeated everytime the engine is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_counts_and_avarages(id_rating_tuple):\n",
    "    nrating = len(id_rating_tuple[1])\n",
    "    return id_rating_tuple[0], (nrating, float(sum(x for x in id_rating_tuple[1])) / nrating)\n",
    "\n",
    "class RecommendationEngine:\n",
    "    \n",
    "    def __count_and_average_ratings(self):\n",
    "        loger.info(\"Counting movie ratings...\")\n",
    "        movieId_ratings_RDD = self.ratings_RDD.map(lambda x: (x[1], x[2])).groupByKey()\n",
    "        movieId_avg_ratings_RDD = movieId_ratings_RDD.map(get_counts_and_avarages)\n",
    "        self.movies_rating_counts_RDD = movieId_avg_ratings_RDD.map(lambda x: (x[0], x[1][0]))\n",
    "        \n",
    "    def __train_model(self):\n",
    "        logger.info(\"Training the ALS model...\")\n",
    "        self.model = ALS.train(self.ratings_RDD, self.rank, seed = self.seed,\n",
    "                              iterations = self.iterations, lambda_ = self.regularization_parameter)\n",
    "        logger.info(\"ALS model built!\")\n",
    "    \n",
    "    def __init__(self, sc, dataset_path):\n",
    "        logger.info(\"Starting up the Recommendation Engine: \")\n",
    "        \n",
    "        self.sc = sc\n",
    "        \n",
    "        #Load ratings data\n",
    "        logger.info(\"Loading ratings data...\")\n",
    "        ratings_file_path = os.path.join(dataset_path, 'ratings.csv')\n",
    "        ratings_raw_RDD = self.sc.textFile(ratings_file_path)\n",
    "        ratings_raw_header = ratings_raw_RDD.take(1)[0]\n",
    "        self.ratings_RDD = ratings_raw_RDD.filter(lambda line: line!=ratings_raw_header) \\\n",
    "        .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]), int(tokens[1]), float(tokens[2]))).cache()\n",
    "        \n",
    "        #Load movies data\n",
    "        logger.info(\"Loading movies data...\")\n",
    "        movies_file_path = os.path.join(dataset_path, 'movies.csv')\n",
    "        movies_raw_RDD = self.sc.textFile(movies_file_path)\n",
    "        movies_raw_header = movies_raw_RDD.take(1)[0]\n",
    "        self.movies_RDD = movies_raw_RDD.filter(lambda line: line!=movies_raw_header) \\\n",
    "        .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]), tokens[1], tokens[2])).cache()\n",
    "        self.movies_titles_RDD = self.movies_RDD.map(lambda x: (int(x[0]), x[1])).cache()\n",
    "        \n",
    "        #Pre-compute movies ratings counts\n",
    "        self.__count_and_average_ratings()\n",
    "        \n",
    "        #Train the model\n",
    "        self.rank = 4\n",
    "        self.seed = 5L\n",
    "        self.iterations = 10\n",
    "        self.regularization_parameter = 0.1\n",
    "        self.__train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add new ratings\n",
    "\n",
    "We need to re-compute the prediction model for every new batch for user ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_ratings(self, ratings):\n",
    "    #Convert new user ratings to RDD\n",
    "    new_ratings_RDD = self.sc.parallelize(ratings)\n",
    "    #Add new ratings to the existing ones\n",
    "    self.ratings_RDD = self.ratings_RDD.union(new_ratings_RDD)\n",
    "    #Re-compute movie ratings count\n",
    "    self.__count_and_average_ratings()\n",
    "    #Re-train the ALS model\n",
    "    self.__train_model()\n",
    "    \n",
    "    return ratings\n",
    "\n",
    "RecommendationEngine.add_ratings = add_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make recommendations\n",
    "\n",
    "We make recommendations based on the new model and excluding those with less than 25 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def __predict_ratings(self, user_movie_RDD):\n",
    "    \n",
    "    predicted_RDD = self.model.predictAll(user_movie_RDD)\n",
    "    predicted_rating_RDD = predicted_RDD.map(lambda x: (x.product, x.rating))\n",
    "    predicted_rating_title_count_RDD = \\\n",
    "        predicted_rating_RDD.join(self.movies_titles_RDD).join(self.movies_rating_counts_RDD)\n",
    "    predicted_rating_title_count_RDD = \\\n",
    "        predicted_rating_title_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))\n",
    "    \n",
    "    return predicted_rating_title_count_RDD\n",
    "\n",
    "def get_top_ratings(self, user_id, movies_count):\n",
    "    \n",
    "    #Get pairs of (userId, movieId) for user_id unrated movies\n",
    "    user_unrated_movies_RDD = self.ratings_RDD.filter(lambda rating: not rating[1]==user_id).map(lambda x: (user_id, x[1]))\n",
    "    \n",
    "    #Get predictions ratings\n",
    "    ratings = self.__predict_ratings(user_unrated_movies_RDD).filter(lambda r: r[2] >= 25).takeOrdered(movies_count, key = lambda x: -x[1])\n",
    "    \n",
    "    return ratings\n",
    "\n",
    "def get_ratings_for_movie_id(self, user_id, movie_id):\n",
    "    \n",
    "    requested_movies_RDD = self.sc.parallelize(movie_id).map(lambda x: (user_id, x))\n",
    "    ratings = self.__predict_ratings(requested_movies_RDD).collect()\n",
    "    \n",
    "    return ratings\n",
    "\n",
    "RecommendationEngine.__predict_ratings = __predict_ratings\n",
    "RecommendationEngine.get_top_ratings = get_top_ratings\n",
    "RecommendationEngine.get_ratings_from_movie_id = get_ratings_from_movie_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build API using Flask\n",
    "\n",
    "[Flask](http://flask.pocoo.org/) is a web microframework for Python. You can easily start up a web API by just importing in your script and use some annotations to associate your service end-points with Python functions. We will wrap the RecommendationEngine we built earlier around some of these end-points and interchange JSON formatted data with the web client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from flask import Blueprint\n",
    "main = Blueprint('main', __name__)\n",
    "\n",
    "import json\n",
    "#from engine import RecommendationEngine\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from flask import Flask, request\n",
    "\n",
    "@main.route(\"/<int:user_id>/ratings/top/<int:count>\", methods=[\"GET\"])\n",
    "def top_ratings(user_id, count):\n",
    "    logger.debug(\"User %s Top ratings requested.\", user_id)\n",
    "    top_ratings = recommendation_engine.get_top_ratings(user_id, count)\n",
    "    return json.dumps(top_ratings)\n",
    "\n",
    "@main.route(\"/<int:user_id>/ratings/<int:movie_id>\", method=[\"GET\"])\n",
    "def movie_ratings(user_id, movie_id):\n",
    "    logger.debug(\"User %s rating requested for movie %s\", user_id, movie_id)\n",
    "    ratings = recommendation_engine.get_ratings_for_movie_id(user_id, [movie_id])\n",
    "    return json.dumps(ratings)\n",
    "\n",
    "@main.route(\"/<int:user_id>/ratings\", method = [\"POST\"])\n",
    "def add_ratings(user_id):\n",
    "    ratings_list = request.form.keys()[0].strip().split(\"\\n\")\n",
    "    ratings_list = map(lambda x: x.split(\",\"), ratings_list)\n",
    "    ratings = map(lambda x: (user_id, int(x[0]), float(x[1])), ratings_list)\n",
    "    recommendation_engine.add_ratings(ratings)\n",
    "    \n",
    "    return json.dump(ratings)\n",
    "\n",
    "def create_app(spark_context, dataset_path):\n",
    "    global recommendation_engine\n",
    "    \n",
    "    recommendation_engine = RecommendationEngine(spark_context, dataset_path)\n",
    "    \n",
    "    app = Flask(__name__)\n",
    "    app.register_blueprint(main)\n",
    "    return app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The application is initialized when calling <font face=\"chalkboard\">create_app</font>. The <font face=\"chalkboard\">RecommendationEngine</font> is created and then we associate the @main.route annotations defined above. Each annotation is defined by:\n",
    "- A route, that is it's URL and may contain parameters between <>. They are mapped to the function arguments\n",
    "- A list of HTTP available methods\n",
    "In the above code, we have:\n",
    "- <font face=\"chalkboard\"> GET /<user_id>/ratings/top </font> get top recommendations for from the engine\n",
    "- <font face=\"chalkboard\"> GET /<user_id>/ratings </font> get predicted rating for a particular movie\n",
    "- <font face=\"chalkboard\"> POST /<user_id>/ratings </font> add new ratings. The format is a series of lines (each ending with the newline separator)\n",
    "with movie_id and rating separated by commas. e.g.\n",
    "\n",
    "260,9  \n",
    "1,8  \n",
    "16,7  \n",
    "25,8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Deploy server using CherryPy\n",
    "\n",
    "[CherryPy](http://cherrypy.org/) is a pythonic, object-oriented web framework, it allows user to build web application as building any object-oriented Python program. So we can use it to build a reliable, HTTP/1.1-compliant, WSGI thred-pooled webserver, it's also to run multiple HTTP servers at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:engine:Starting up the Recommendation Engine: \n",
      "INFO:engine:Loading Ratings data...\n",
      "INFO:engine:Loading Movies data...\n",
      "INFO:engine:Counting movie ratings...\n",
      "INFO:engine:Training the ALS model...\n"
     ]
    }
   ],
   "source": [
    "import time, sys, cherrypy, os\n",
    "from paste.translogger import TransLogger\n",
    "from app import create_app\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "def init_spark_context():\n",
    "    #Load spark context\n",
    "    conf = SparkConf().setAppName(\"movie_recommendation-server\")\n",
    "    #pass additional python modules to each worker\n",
    "    sc = SparkContext(conf = conf, pyFiles=['engine.py', 'app.py'])\n",
    "    \n",
    "    return sc\n",
    "\n",
    "def run_server(app):\n",
    "    #enable WSGI access logging via Paste\n",
    "    app_logged = Translogger(app)\n",
    "    \n",
    "    #Mount the WSTI callable object(app) on the root directory\n",
    "    cherrypy.tree.graft(app_logged, '/')\n",
    "    \n",
    "    #Set the configuration of the web server\n",
    "    cherrypy.config.update({\n",
    "            'engine.autoreload.on': True,\n",
    "            'log.screen': True,\n",
    "            'server.socket_port': 5432,\n",
    "            'server.socket_host': '0.0.0.0'\n",
    "        })\n",
    "    \n",
    "    #Start the CherryPy WSGI web server\n",
    "    cherrypy.engine.start()\n",
    "    cherrypy.engine.block()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    #Init spark context and load libraries\n",
    "    try:\n",
    "        sc.stop()\n",
    "    except:\n",
    "        pass\n",
    "    sc = init_spark_context()\n",
    "    dataset_path = os.path.join('data', 'ml-latest')\n",
    "    app = create_app(sc, dataset_path)\n",
    "    \n",
    "    #start web server\n",
    "    run_server(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We did three things above:\n",
    "- Create a spark context as defined in the function init_spark_context, passing additional Python modules.\n",
    "- Create the Flask app calling the create_app we defined in app.py\n",
    "- Run the server itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Run server with Spark\n",
    "\n",
    "In order to have the server being able to access a Spark context and cluster, we need to submit the server.py file to pySpark by using spark-submit. I use some command like <font face='chalkboard'>~/spark-2.1.0/bin/spark-submit --master local --total-executor-cores 14 --executor-memory 6g server.py</font>. Where:\n",
    "\n",
    "- We use <font face='chalkboard'>spark-submit</font> not <font face='chalkboard'>pyspark</font> directly\n",
    "- The <font face='chalkboard'>--master</font> parameter should point to your Spark cluster setup. (Here I use local)\n",
    "- We pass additional configuration parameters like <font face='chalkboard'>--total-executor-cores</font> and <font face='chalkboard'>--executor-memory</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the service\n",
    "Once the service is running, we can use it to predict top ratings for a given user.\n",
    "\n",
    "### Post new ratings\n",
    "The first thing that's needed is to add user ratings to the existing data and train a model. We can use <font face='chalkboard'>curl</font> to post new ratings from shell. Have the ratings formatted in <font face='chalkboard'>user_ratings.txt</font> and then execute the following command:\n",
    "\n",
    "<font face='chalkboard'>curl --data-binary @user_ratings.file http://<SERVER_IP>:5432/0/ratings</font>\n",
    "\n",
    "Spark will run some computation as described in our <font face='chalkboard'>add_rating()</font> function in <font face='chalkboard'>engine.py</font>.\n",
    "\n",
    "### Get top recommendations\n",
    "\n",
    "Go to <font face='chalkboard'>http://<SERVER_IP>:5432/0/ratings/top/10</font>, you will see top 10 movie recommended for the user.\n",
    "\n",
    "### Get movie prediction\n",
    "\n",
    "Go to <font face='chalkboard'>http://<SERVER_IP>:5432/0/ratings/500</font> to get the predicted rating for movie <font face='chalkboard'>Mrs. Doubtfire (1993)</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
